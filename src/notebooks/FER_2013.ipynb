{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef5483f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T23:12:55.762328Z",
     "iopub.status.busy": "2025-08-06T23:12:55.762057Z",
     "iopub.status.idle": "2025-08-06T23:12:55.766347Z",
     "shell.execute_reply": "2025-08-06T23:12:55.765653Z",
     "shell.execute_reply.started": "2025-08-06T23:12:55.762306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "\n",
    "FER_213_PATH = \"/kaggle/input/fer2013/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cf3ce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T23:12:57.791096Z",
     "iopub.status.busy": "2025-08-06T23:12:57.790825Z",
     "iopub.status.idle": "2025-08-06T23:12:57.852986Z",
     "shell.execute_reply": "2025-08-06T23:12:57.852289Z",
     "shell.execute_reply.started": "2025-08-06T23:12:57.791074Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3643ff0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T23:12:58.941123Z",
     "iopub.status.busy": "2025-08-06T23:12:58.940855Z",
     "iopub.status.idle": "2025-08-06T23:12:58.945975Z",
     "shell.execute_reply": "2025-08-06T23:12:58.945374Z",
     "shell.execute_reply.started": "2025-08-06T23:12:58.941102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Getting data ready\n",
    "tranform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a9c757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T23:13:00.153119Z",
     "iopub.status.busy": "2025-08-06T23:13:00.152825Z",
     "iopub.status.idle": "2025-08-06T23:13:34.074771Z",
     "shell.execute_reply": "2025-08-06T23:13:34.074143Z",
     "shell.execute_reply.started": "2025-08-06T23:13:00.153097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Options: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "Number of training samples: 22967\n",
      "Number of validation samples: 5742\n"
     ]
    }
   ],
   "source": [
    "# Importing dataset\n",
    "dataset = datasets.ImageFolder(root=FER_213_PATH, transform=tranform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Classification Options:\", dataset.class_to_idx)\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of validation samples:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7dd9c6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T23:13:55.328874Z",
     "iopub.status.busy": "2025-08-06T23:13:55.328144Z",
     "iopub.status.idle": "2025-08-06T23:13:56.916203Z",
     "shell.execute_reply": "2025-08-06T23:13:56.915400Z",
     "shell.execute_reply.started": "2025-08-06T23:13:55.328844Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 185MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 7]           3,591\n",
      "================================================================\n",
      "Total params: 11,180,103\n",
      "Trainable params: 8,397,319\n",
      "Non-trainable params: 2,782,784\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 106.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load a pretrained RestNet18 model\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchsummary import summary\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "\n",
    "# Modify the final layer for 7 classes\n",
    "model.fc = nn.Linear(model.fc.in_features, 7)\n",
    "\n",
    "# Transfer learning only on the last residual block and the final fully connected\n",
    "for name, param, in model.named_parameters():\n",
    "    if \"layer4\" not in name and \"fc\" not in name:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3de09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T23:14:04.732449Z",
     "iopub.status.busy": "2025-08-06T23:14:04.731600Z",
     "iopub.status.idle": "2025-08-06T23:14:04.737016Z",
     "shell.execute_reply": "2025-08-06T23:14:04.736303Z",
     "shell.execute_reply.started": "2025-08-06T23:14:04.732414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b224b3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T23:17:09.625104Z",
     "iopub.status.busy": "2025-08-06T23:17:09.624571Z",
     "iopub.status.idle": "2025-08-06T23:35:51.807193Z",
     "shell.execute_reply": "2025-08-06T23:35:51.806509Z",
     "shell.execute_reply.started": "2025-08-06T23:17:09.625071Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 1.5317, Train Accuracy: 40.84%, Val Accuracy: 41.55%\n",
      "Epoch [2/30], Loss: 1.4667, Train Accuracy: 43.35%, Val Accuracy: 42.96%\n",
      "Epoch [3/30], Loss: 1.4273, Train Accuracy: 44.90%, Val Accuracy: 45.89%\n",
      "Epoch [4/30], Loss: 1.3859, Train Accuracy: 47.13%, Val Accuracy: 44.95%\n",
      "Epoch [5/30], Loss: 1.3663, Train Accuracy: 47.96%, Val Accuracy: 44.95%\n",
      "Epoch [6/30], Loss: 1.3374, Train Accuracy: 49.20%, Val Accuracy: 46.45%\n",
      "Epoch [7/30], Loss: 1.3163, Train Accuracy: 49.63%, Val Accuracy: 46.59%\n",
      "Epoch [8/30], Loss: 1.2909, Train Accuracy: 50.99%, Val Accuracy: 46.45%\n",
      "Epoch [9/30], Loss: 1.2681, Train Accuracy: 51.89%, Val Accuracy: 47.58%\n",
      "Epoch [10/30], Loss: 1.2465, Train Accuracy: 52.45%, Val Accuracy: 47.37%\n",
      "Epoch [11/30], Loss: 1.2253, Train Accuracy: 53.65%, Val Accuracy: 47.47%\n",
      "Epoch [12/30], Loss: 1.2045, Train Accuracy: 54.59%, Val Accuracy: 48.64%\n",
      "Epoch [13/30], Loss: 1.1864, Train Accuracy: 55.06%, Val Accuracy: 49.20%\n",
      "Epoch [14/30], Loss: 1.1588, Train Accuracy: 56.19%, Val Accuracy: 47.98%\n",
      "Epoch [15/30], Loss: 1.1406, Train Accuracy: 57.18%, Val Accuracy: 48.62%\n",
      "Epoch [16/30], Loss: 1.1302, Train Accuracy: 57.72%, Val Accuracy: 48.87%\n",
      "Epoch [17/30], Loss: 1.1058, Train Accuracy: 58.52%, Val Accuracy: 49.18%\n",
      "Epoch [18/30], Loss: 1.0438, Train Accuracy: 61.41%, Val Accuracy: 49.20%\n",
      "Early stopping triggered, training stopped.\n",
      "Best validation accuracy: 49.20%\n",
      "Training complete. Model saved as 'best_FER_2013_model.pth'.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 30\n",
    "best_val_accuracy = 0.0\n",
    "patience = 5\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    # Validation data\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    scheduler.step(val_acc)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_acc:.2f}%, Val Accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_FER_2013_model.pth')\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered, training stopped.\")\n",
    "            break\n",
    "\n",
    "# Some verbose output\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.2f}%\")\n",
    "print(\"Training complete. Model saved as 'best_FER_2013_model.pth'.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 786787,
     "sourceId": 1351797,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
