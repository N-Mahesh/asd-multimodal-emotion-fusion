{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1af4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "import tempfile\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "\n",
    "SAMPLE_RATE = 16000            # model expects 16 kHz\n",
    "CHANNELS = 1\n",
    "CHUNK_SEC = 1.0                # record chunk length\n",
    "HOP_SEC = 0.5                  \n",
    "PRINT_INTERVAL_SEC = 0.5       # how often to print an update\n",
    "SMOOTHING_ALPHA = 0.6          \n",
    "\n",
    "MODEL_ID = \"iic/emotion2vec_plus_base\"\n",
    "\n",
    "emo = pipeline(\n",
    "    task=Tasks.emotion_recognition,\n",
    "    model=MODEL_ID\n",
    ")\n",
    "\n",
    "MODEL_LABELS = None\n",
    "\n",
    "audio_q = queue.Queue(maxsize=10)\n",
    "stop_flag = threading.Event()\n",
    "\n",
    "def audio_producer():\n",
    "    frame_len = int(SAMPLE_RATE * CHUNK_SEC)\n",
    "    hop_len = int(SAMPLE_RATE * HOP_SEC)\n",
    "    ring = deque(maxlen=frame_len)\n",
    "\n",
    "    def callback(indata, frames, time_info, status):\n",
    "        if status:\n",
    "            print(f\"[audio status] {status}\")\n",
    "        mono = indata[:, 0] if indata.ndim > 1 else indata\n",
    "        ring.extend((mono * 32767).astype(np.int16))\n",
    "\n",
    "        if len(ring) == frame_len:\n",
    "            chunk = np.array(ring, dtype=np.int16)\n",
    "            try:\n",
    "                audio_q.put_nowait(chunk)\n",
    "            except queue.Full:\n",
    "                pass\n",
    "            for _ in range(hop_len):\n",
    "                if ring:\n",
    "                    ring.popleft()\n",
    "\n",
    "    with sd.InputStream(\n",
    "        samplerate=SAMPLE_RATE,\n",
    "        channels=CHANNELS,\n",
    "        dtype=\"float32\",\n",
    "        callback=callback,\n",
    "        blocksize=int(SAMPLE_RATE * 0.05),\n",
    "    ):\n",
    "        while not stop_flag.is_set():\n",
    "            time.sleep(0.1)\n",
    "\n",
    "def run_model_on_wav_bytes(int16_pcm):\n",
    "    \"\"\"Write a temp wav and call the ModelScope pipeline with frame granularity.\"\"\"\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as tmp:\n",
    "        wavfile.write(tmp.name, SAMPLE_RATE, int16_pcm)\n",
    "        res = emo(tmp.name, granularity=\"frame\", extract_embedding=False)\n",
    "        return res\n",
    "    \n",
    "def infer_consumer():\n",
    "    global MODEL_LABELS\n",
    "\n",
    "    ewma_scores = None\n",
    "    last_print = 0.0\n",
    "\n",
    "    while not stop_flag.is_set():\n",
    "        try:\n",
    "            pcm = audio_q.get(timeout=0.2)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "\n",
    "        res = run_model_on_wav_bytes(pcm)\n",
    "\n",
    "        labels = res.get(\"labels\")\n",
    "        scores = res.get(\"scores\")\n",
    "\n",
    "        if labels is None or scores is None:\n",
    "            detail = res.get(\"detail\") or {}\n",
    "            labels = labels or detail.get(\"labels\")\n",
    "            scores = scores or detail.get(\"scores\")\n",
    "\n",
    "        if labels is None or scores is None:\n",
    "            print(\"[warn] Unexpected pipeline output keys:\", res)\n",
    "            continue\n",
    "\n",
    "        if MODEL_LABELS is None:\n",
    "            MODEL_LABELS = labels\n",
    "\n",
    "        scores = np.array(scores)\n",
    "\n",
    "        if scores.ndim == 1:\n",
    "            scores = scores[None, :]\n",
    "\n",
    "        eps = 1e-8\n",
    "        scores = np.clip(scores, eps, None)\n",
    "        scores = scores / (scores.sum(axis=1, keepdims=True) + eps)\n",
    "\n",
    "        chunk_mean = scores.mean(axis=0)\n",
    "\n",
    "        if ewma_scores is None:\n",
    "            ewma_scores = chunk_mean\n",
    "        else:\n",
    "            ewma_scores = SMOOTHING_ALPHA * ewma_scores + (1.0 - SMOOTHING_ALPHA) * chunk_mean\n",
    "\n",
    "        now = time.time()\n",
    "        if now - last_print >= PRINT_INTERVAL_SEC:\n",
    "            last_print = now\n",
    "            top_idx = int(np.argmax(ewma_scores))\n",
    "            top_label = MODEL_LABELS[top_idx] if MODEL_LABELS else f\"class_{top_idx}\"\n",
    "            top_conf = float(ewma_scores[top_idx])\n",
    "\n",
    "            top3_idx = np.argsort(-ewma_scores)[:3]\n",
    "            leaderboard = \", \".join(\n",
    "                f\"{MODEL_LABELS[i]} {ewma_scores[i]:.2f}\" for i in top3_idx\n",
    "            )\n",
    "            print(f\"[live] {top_label:<10} {top_conf:.2f} | {leaderboard}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading model:\", MODEL_ID)\n",
    "    print(\"Starting mic… \")\n",
    "    prod = threading.Thread(target=audio_producer, daemon=True)\n",
    "    cons = threading.Thread(target=infer_consumer, daemon=True)\n",
    "    prod.start()\n",
    "    cons.start()\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping…\")\n",
    "        stop_flag.set()\n",
    "        prod.join(timeout=2.0)\n",
    "        cons.join(timeout=2.0)\n",
    "        print(\"Goodbye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f5a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.emotion_recognition,\n",
    "    model=\"iic/emotion2vec_plus_base\")\n",
    "\n",
    "rec_result = inference_pipeline('SOME.wav', granularity=\"utterance\", extract_embedding=False)\n",
    "print(rec_result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
